{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import norm\n",
    "import sklearn\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downloading sketch info (SF takes a while) \n",
    "SF = pickle.load(open('/tigress/rslee/SF.p', 'rb'))\n",
    "S = pickle.load(open('/tigress/rslee/S.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metadata files: 35\n",
      "Number of metadata trials for models: 1400\n"
     ]
    }
   ],
   "source": [
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path)\n",
    "              for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "path_to_sketches = '/home/rslee/sketch_data'\n",
    "\n",
    "def get_trial_ID_from_metadata(path):\n",
    "    metadata = pd.read_csv(path)[['wID', 'trial','target']]\n",
    "    trialID = [\"%s_trial_%s_%s\" % (metadata['wID'].values[row], metadata['trial'].values[row], metadata['target'].values[row])\n",
    "               for row in xrange(0,len(metadata))]\n",
    "    return trialID\n",
    "\n",
    "def get_viewpoint_from_metadata(path):\n",
    "    return pd.read_csv(path).viewpoint.values.tolist()\n",
    "\n",
    "def get_competitor_from_metadata(path):\n",
    "    return pd.read_csv(path).competitor.values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "metadata_paths = list_files(path_to_sketches, ext='csv') \n",
    "trialID_metadata = sum(map(get_trial_ID_from_metadata, metadata_paths), [])\n",
    "viewpoint_sketches = np.asarray(sum(map(get_viewpoint_from_metadata, metadata_paths),[]))\n",
    "competitor_sketches = np.asarray(sum(map(get_competitor_from_metadata, metadata_paths),[]))\n",
    "\n",
    "print 'Number of metadata files: ' + str(len(metadata_paths))\n",
    "print 'Number of metadata trials for models: ' + str(len(viewpoint_sketches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting the metadata to be sorted correctly. \n",
    "\n",
    "inds_metadata = np.argsort(trialID_metadata)\n",
    "_trialID_metadata = np.asarray(trialID_metadata)[inds_metadata]\n",
    "_SVP_bt = np.asarray(viewpoint_sketches)[inds_metadata]\n",
    "_comp_bt = np.asarray(competitor_sketches)[inds_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SL = np.array(S.label)\n",
    "# normalize and get means of feature vectors\n",
    "\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "def get_class_means(X, labels):\n",
    "    # load in and normalize features \n",
    "    X = normalize(X)\n",
    "    _mu = np.zeros((len(np.unique(np.asarray(labels))), X.shape[1]), float)\n",
    "    for vi, v in enumerate(np.unique(np.asarray(labels))):\n",
    "        Xv = X[labels == v]\n",
    "        nv = float(Xv.shape[0])\n",
    "        if nv > 0:\n",
    "\n",
    "            _mu[vi] = Xv.mean(0)\n",
    "    return _mu\n",
    "\n",
    "\n",
    "def get_means_across_views(X, labels, viewpoints): \n",
    "    _mu = np.zeros((len(np.unique(viewpoints)) * len(FURNITURES), X.shape[1]),float) # saving the averaged SF per laer here \n",
    "    for obj_i, obj in enumerate(FURNITURES):\n",
    "        inds_object = np.where(labels == obj)\n",
    "        X_obj = X[inds_object] # taking all the views per object here \n",
    "        \n",
    "        means = get_class_means(X_obj, viewpoints[inds_object])\n",
    "        \n",
    "        _mu[obj_i * len(np.unique(viewpoints)): (obj_i + 1) * len(np.unique(viewpoints)), :] = means\n",
    "    return _mu\n",
    "        \n",
    "_SF_bt = []\n",
    "for layer in xrange(0,7):\n",
    "    inds = np.argsort(S.trialID.values)\n",
    "    SF_i = SF[layer]\n",
    "    _SF_bt.append(SF_i[inds])\n",
    "_SL_bt = SL[inds]\n",
    "S_subj = S.subj.values\n",
    "_S_subj_bt = S_subj[inds]\n",
    "_S_trial_bt = S.trial.values[inds]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'load_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d8367de97c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mSP_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# used for the batch index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# take out the fourth dimension, alpha, which controls transparency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'load_image'"
     ]
    }
   ],
   "source": [
    "# getting pixel level data \n",
    "VGG_SIZE_X, VGG_SIZE_Y = 224, 224\n",
    "VGG_SIZE_Z = 3\n",
    "\n",
    "SP = np.empty((num_sketches, VGG_SIZE_X * VGG_SIZE_Y* VGG_SIZE_Z), float)\n",
    "SP_i = 0 # used for the batch index \n",
    "for path in S.path: \n",
    "    img = utils.load_image(path)\n",
    "    # take out the fourth dimension, alpha, which controls transparency\n",
    "    img = img[:,:,:3]\n",
    "\n",
    "    img = np.asarray(img.flatten()).reshape(1, VGG_SIZE_X * VGG_SIZE_Y* VGG_SIZE_Z)\n",
    "          \n",
    "    SP[SP_i, :] = img\n",
    "    SP_i += 1 \n",
    "\n",
    "inds = np.argsort(S.trialID.values)\n",
    "_SP_bt = SP[inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0119172_neurosketch' '0119173_neurosketch' '0120173_neurosketch'\n",
      " '0123171_neurosketch' '0125172_neurosketch' '1121161_neurosketch'\n",
      " '1202161_neurosketch' '1206161_neurosketch' '1206162_neurosketch'\n",
      " '1206163_neurosketch' '0110171_neurosketch' '0110172_neurosketch'\n",
      " '0111171_neurosketch' '0113171_neurosketch' '0115172_neurosketch'\n",
      " '0119171_neurosketch' '0119172_neurosketch' '0119173_neurosketch'\n",
      " '0120173_neurosketch' '0123171_neurosketch' '0125172_neurosketch'\n",
      " '1121161_neurosketch' '1202161_neurosketch' '1206161_neurosketch'\n",
      " '1206162_neurosketch' '1206163_neurosketch' '0110171_neurosketch'\n",
      " '0110172_neurosketch' '0111171_neurosketch' '0113171_neurosketch'\n",
      " '0115172_neurosketch' '0119171_neurosketch' '0119172_neurosketch'\n",
      " '0119173_neurosketch' '0120173_neurosketch' '0123171_neurosketch'\n",
      " '0125172_neurosketch' '1121161_neurosketch' '1202161_neurosketch'\n",
      " '1206161_neurosketch' '1206162_neurosketch' '1206163_neurosketch'\n",
      " '0110171_neurosketch' '0110172_neurosketch' '0111171_neurosketch'\n",
      " '0113171_neurosketch' '0115172_neurosketch' '0119171_neurosketch'\n",
      " '0119172_neurosketch' '0119173_neurosketch' '0120173_neurosketch'\n",
      " '0123171_neurosketch' '0125172_neurosketch' '1121161_neurosketch'\n",
      " '1202161_neurosketch' '1206161_neurosketch' '1206162_neurosketch'\n",
      " '1206163_neurosketch' '0110171_neurosketch' '0110172_neurosketch'\n",
      " '0111171_neurosketch' '0113171_neurosketch' '0115172_neurosketch'\n",
      " '0119171_neurosketch' '0119172_neurosketch' '0119173_neurosketch'\n",
      " '0120173_neurosketch' '0123171_neurosketch' '0125172_neurosketch'\n",
      " '1121161_neurosketch' '1202161_neurosketch' '1206161_neurosketch'\n",
      " '1206162_neurosketch' '1206163_neurosketch' '0110171_neurosketch'\n",
      " '0110172_neurosketch' '0111171_neurosketch' '0113171_neurosketch'\n",
      " '0115172_neurosketch' '0119171_neurosketch' '0119172_neurosketch'\n",
      " '0119173_neurosketch' '0120173_neurosketch' '0123171_neurosketch'\n",
      " '0125172_neurosketch' '1121161_neurosketch' '1202161_neurosketch'\n",
      " '1206161_neurosketch' '1206162_neurosketch' '1206163_neurosketch'\n",
      " '0110171_neurosketch' '0110172_neurosketch' '0111171_neurosketch'\n",
      " '0113171_neurosketch' '0115172_neurosketch' '0119171_neurosketch'\n",
      " '0119172_neurosketch' '0119173_neurosketch' '0120173_neurosketch'\n",
      " '0123171_neurosketch' '0125172_neurosketch' '1121161_neurosketch'\n",
      " '1202161_neurosketch' '1206161_neurosketch' '1206162_neurosketch'\n",
      " '1206163_neurosketch' '0110171_neurosketch' '0110172_neurosketch'\n",
      " '0111171_neurosketch' '0113171_neurosketch']\n",
      "[ 8  8  8  8  8  8  8  8  8  8 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 18\n",
      " 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 20 20 20 20 20 20 20 20 20 20\n",
      " 20 20 20 20 20 20 22 22 22 22]\n",
      "['bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed' 'bed'\n",
      " 'bed' 'bed']\n",
      "Checking that the indexing is correct: True\n"
     ]
    }
   ],
   "source": [
    "# setting the index right for the sketches\n",
    "\n",
    "\n",
    "inds_final = np.lexsort((np.asarray(_S_subj_bt), _SVP_bt.astype(int), np.asarray(_SL_bt)))\n",
    "_SVP = _SVP_bt[inds_final]\n",
    "_SL = _SL_bt[inds_final]\n",
    "_S_subj = _S_subj_bt[inds_final]\n",
    "_S_trial = _S_trial_bt[inds_final]\n",
    "_comp = _comp_bt[inds_final]\n",
    "# _SP = _SP_bt[inds_final]\n",
    "_SF = []\n",
    "for layer in xrange(0,7):\n",
    "    _SF_i = _SF_bt[layer]\n",
    "    _SF.append(_SF_i[inds_final])\n",
    "\n",
    "check1 = _trialID_metadata[inds_final]\n",
    "check2 = S.trialID.values[np.argsort(S.trialID.values)][inds_final]\n",
    "\n",
    "print _S_subj[70:180]\n",
    "print _SVP[70:180]\n",
    "print _SL[70:180]\n",
    "print (\"Checking that the indexing is correct: \" + str(np.array_equal(check1, check2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_axes = ['bed_bench','bed_chair','bed_table','bench_chair','bench_table','chair_table']\n",
    "\n",
    "def assign_axis_to_metadata(labels, competitor):\n",
    "    _combos = [i+'_'+j for (i,j) in zip(list(np.asarray(labels)),list(np.asarray(competitor)))]\n",
    "    lookup = {'bed_bench':'bed_bench',\n",
    "              'bench_bed':'bed_bench',\n",
    "              'bed_chair':'bed_chair',\n",
    "              'chair_bed':'bed_chair',\n",
    "              'bed_table':'bed_table',\n",
    "              'table_bed':'bed_table',\n",
    "              'bench_chair':'bench_chair',\n",
    "              'chair_bench':'bench_chair',\n",
    "              'bench_table':'bench_table',\n",
    "              'table_bench':'bench_table',\n",
    "              'chair_table':'chair_table',\n",
    "              'table_chair':'chair_table',          \n",
    "             }\n",
    "    axis = [lookup[c] for c in _combos]\n",
    "\n",
    "    return axis\n",
    "\n",
    "_axis = assign_axis_to_metadata(_SL, _comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within_run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-83ffa129b5a2>(40)<module>()\n",
      "-> assert s.shape==(SIM.shape[2],)\n",
      "(Pdb) SIM.shape\n",
      "(35, 37)\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-83ffa129b5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0msub_spearman2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-83ffa129b5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0msub_spearman2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rslee/.conda/envs/pytorch/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rslee/.conda/envs/pytorch/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "LAYERS_NM = ['pixel', 'pool1', 'pool2', 'pool3', 'pool4', 'pool5', 'fc6', 'fc7']\n",
    "\n",
    "  \n",
    "for i in reversed(xrange(0,7)):\n",
    "    which_feat = LAYERS_NM[i]\n",
    "    FEATMAT = _SF[i]\n",
    "    # width of moving window in # of trials    \n",
    "    window_size = 4 \n",
    "    first_trial = int(min(_S_trial.astype(int)))\n",
    "    last_trial = int(max(_S_trial.astype(int)))\n",
    "    num_windows = last_trial-first_trial-window_size+2 ##     \n",
    "\n",
    "    SIM = []\n",
    "    subs = np.unique(_S_subj)\n",
    "    for sub in subs:\n",
    "        sim = []\n",
    "        for n in np.arange(num_windows):\n",
    "            start = first_trial + n\n",
    "            end = first_trial + n + window_size\n",
    "            span = np.arange(start,end)\n",
    "            axis = np.unique(np.asarray(_axis)[_S_subj==sub])[0]\n",
    "            o1 = axis.split('_')[0]\n",
    "            o2 = axis.split('_')[1]\n",
    "            o1_inds = (_SL==o1) & (_S_subj==sub) & (pd.to_numeric(_S_trial)>=start) & (pd.to_numeric(_S_trial)<=end)\n",
    "            o2_inds = (_SL==o2) & (_S_subj==sub) & (pd.to_numeric(_S_trial)>=start) & (pd.to_numeric(_S_trial)<=end)\n",
    "            FEAT_o1 = FEATMAT[o1_inds]\n",
    "            FEAT_o2 = FEATMAT[o2_inds]\n",
    "            MEANFEAT_o1 = FEATMAT[o1_inds].mean(0)\n",
    "            MEANFEAT_o2 = FEATMAT[o2_inds].mean(0)\n",
    "            sim.append(stats.pearsonr(MEANFEAT_o1,MEANFEAT_o2)[0])\n",
    "        SIM.append(sim)\n",
    "    SIM = np.array(SIM)\n",
    "\n",
    "\n",
    "    ## plot time series across runs of training\n",
    "    sns.set_context('poster')\n",
    "    sns.set_style('dark')\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.xlabel('repetitions')\n",
    "    plt.ylabel('correlation distance')\n",
    "    plt.xlim(0,36)\n",
    "    for i,j in zip([0,10,20,30],[7,17,27,37]):\n",
    "        x_inds = list(np.arange(i,j))\n",
    "        y_vals = 1-SIM.mean(0)[x_inds]\n",
    "        plt.plot(x_inds,y_vals,'k',linewidth=4)\n",
    "    # for i,j in zip([0,10,20,30],[6,16,26,36]):  \n",
    "    #     plt.axvspan(i,j, alpha=0.4, color='red')    \n",
    "    for i,j in zip([6,16,26],[10,20,30]):\n",
    "        plt.axvspan(i,j, alpha=0.75, color='white') \n",
    "    run_labels = ['run 1','run 2','run 3', 'run 4']    \n",
    "    tick = plt.xticks(np.arange(3.5, 36,10.0),run_labels) \n",
    "    plt.tight_layout()\n",
    "    if not os.path.exists('./plots'):\n",
    "        os.makedirs('./plots')\n",
    "    plt.savefig(os.path.join('./plots','similarity_sketch_timecourse_allruns_{}.pdf'.format(which_feat)))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "LAYERS_NM = ['pixel', 'pool1', 'pool2', 'pool3', 'pool4', 'pool5', 'fc6', 'fc7']\n",
    "for i in reversed(xrange(0,7)):\n",
    "    which_feat = LAYERS_NM[i]\n",
    "    FEATMAT = _SF[i]\n",
    "    num_runs = 4\n",
    "    run_length = 10\n",
    "    first_trial = int(min(_S_trial.astype(int)))\n",
    "    last_trial = int(max(_S_trial.astype(int))) \n",
    "\n",
    "    subs = np.unique(_S_subj)\n",
    "    SIM = []\n",
    "    for sub in subs:\n",
    "        Sim = []\n",
    "        for n in np.arange(num_runs):\n",
    "            sim = []\n",
    "            start = first_trial + run_length*n\n",
    "            end = first_trial + run_length*(n+1) - 1\n",
    "            window_size = 4 # width of moving window in # of trials\n",
    "            num_windows = end-start-window_size+2 ## \n",
    "            for _n in np.arange(num_windows):\n",
    "                _start = start + _n\n",
    "                _end = start + _n + window_size                \n",
    "                axis = np.unique(np.asarray(_axis)[_S_subj==sub])[0]\n",
    "                o1 = axis.split('_')[0]\n",
    "                o2 = axis.split('_')[1]\n",
    "                o1_inds = (_SL==o1) & (_S_subj==sub) & (pd.to_numeric(_S_trial)>=_start) & (pd.to_numeric(_S_trial)<=_end)\n",
    "                o2_inds = (_SL==o2) & (_S_subj==sub) & (pd.to_numeric(_S_trial)>=_start) & (pd.to_numeric(_S_trial)<=_end)\n",
    "                FEAT_o1 = FEATMAT[o1_inds]\n",
    "                FEAT_o2 = FEATMAT[o2_inds]\n",
    "                MEANFEAT_o1 = FEAT_o1.mean(0)\n",
    "                MEANFEAT_o2 = FEAT_o2.mean(0)\n",
    "                sim.append(stats.pearsonr(MEANFEAT_o1,MEANFEAT_o2)[0])\n",
    "            Sim.append(sim)\n",
    "        SIM.append(Sim)\n",
    "    SIM = np.array(SIM)\n",
    "    \n",
    "         ## spearman correlation over the mean for each timewindow in each run\n",
    "    sub_spearman2 = []\n",
    "    for i, s in enumerate(SIM.mean(1)):\n",
    "        assert s.shape==(SIM.shape[2],)\n",
    "        sub_spearman2.append(1 - stats.spearmanr(np.arange(SIM.shape[2]),s)[0])    \n",
    "\n",
    "    W = pd.DataFrame([subs,sub_spearman2])\n",
    "    W = W.transpose()\n",
    "    W.columns = ['subj','runwise_similarity_change']\n",
    "    W.to_csv('sketch_similarity_timecourse_within_run_{}.csv'.format(which_feat))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
