{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instructions\n",
    "\n",
    "You'll want to change all of the file names and file locations. They include: \n",
    "\n",
    "path_to_sketches\n",
    "metadata_file\n",
    "dir_path \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deactivate(net):\n",
    "    net.eval()\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad = False  \n",
    "        \n",
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_device = 3\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True)#.cuda(cuda_device)\n",
    "vgg19_features = deepcopy(vgg19.features)\n",
    "vgg19_classifier = deepcopy(vgg19.classifier)\n",
    "\n",
    "conv1 = nn.Sequential(*(list(vgg19.features.children())[slice(0, 5)]))\n",
    "conv2 = nn.Sequential(*(list(vgg19.features.children())[slice(5, 10)]))\n",
    "conv3 = nn.Sequential(*(list(vgg19.features.children())[slice(10, 19)]))\n",
    "conv4 = nn.Sequential(*(list(vgg19.features.children())[slice(19, 28)]))\n",
    "conv5 = nn.Sequential(*(list(vgg19.features.children())[slice(28, 37)]))\n",
    "fc6 = nn.Sequential(*(list(vgg19.classifier.children())[slice(0, 2)]))\n",
    "fc7 = nn.Sequential(*(list(vgg19.classifier.children())[slice(3, 5)]))\n",
    "fc8 = nn.Sequential(list(vgg19.classifier.children())[-1])\n",
    "\n",
    "if use_cuda:\n",
    "    conv1.cuda(cuda_device)\n",
    "    conv2.cuda(cuda_device)\n",
    "    conv3.cuda(cuda_device)\n",
    "    conv4.cuda(cuda_device)\n",
    "    conv5.cuda(cuda_device)\n",
    "    fc6.cuda(cuda_device)    \n",
    "    fc7.cuda(cuda_device)    \n",
    "    fc8.cuda(cuda_device)        \n",
    "        \n",
    "deactivate(conv1)\n",
    "deactivate(conv2)\n",
    "deactivate(conv3)\n",
    "deactivate(conv4)\n",
    "deactivate(conv5)\n",
    "deactivate(fc6)\n",
    "deactivate(fc7)\n",
    "deactivate(fc8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sketches: 1840\n",
      "Number of subjects: 2\n"
     ]
    }
   ],
   "source": [
    "# get labels\n",
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path)\n",
    "              for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "def get_label_from_path(path):\n",
    "    return path.split('/')[-2].split('_')[0]\n",
    "\n",
    "def get_trial_from_path(path):\n",
    "    return path.split('/')[-2].split('_')[-1]\n",
    "\n",
    "def get_subj_from_path(path):\n",
    "    return path.split('/')[-3]\n",
    "\n",
    "\n",
    "def get_psketch_ID_from_path(path):\n",
    "    return path.split('/')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "def get_trial_ID_from_path(path):\n",
    "    return path.split('/')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# extract metadata\n",
    "path_to_sketches = '/home/rslee/partial_s_mini'\n",
    "sketch_paths = list_files(path_to_sketches)\n",
    "sketch_labels = map(get_label_from_path,sketch_paths)\n",
    "trialNum = map(get_trial_from_path,sketch_paths)\n",
    "subj = map(get_subj_from_path,sketch_paths)\n",
    "psketchID = map(get_psketch_ID_from_path, sketch_paths)\n",
    "\n",
    "# trialID = map(get_trial_ID_from_path, sketch_paths)\n",
    "\n",
    "\n",
    "# ensure that sketches are in the right order (by subject, by trial, then by partial SKetch ID) \n",
    "# note: labels are not arranged accordingly. I want this to be as close to the original metadata as possible. \n",
    "# will change to sort by labels > by trialNum if it's easy to copy/arrange the metadata \n",
    "inds_final = np.lexsort((np.asarray(psketchID).astype(int), np.asarray(trialNum).astype(int), subj))\n",
    "_sketch_paths = [sketch_paths[i] for i in inds_final] \n",
    "_sketch_labels = [sketch_labels[i] for i in inds_final] \n",
    "_trialNum = [trialNum[i] for i in inds_final] \n",
    "_subj = [subj[i] for i in inds_final] \n",
    "_psketchID = [psketchID[i] for i in inds_final] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# organize into dataframe\n",
    "S = pd.DataFrame([_subj,_trialNum,_sketch_labels,_sketch_paths, _psketchID])\n",
    "S = S.transpose()\n",
    "S.columns = ['subj','trial','label','path','psketchID']\n",
    "\n",
    "\n",
    "\n",
    "print 'Number of sketches: ' + str(len(sketch_paths))\n",
    "print 'Number of subjects: ' + str(len(np.unique(subj)))\n",
    "\n",
    "num_sketches = len(sketch_paths)\n",
    "num_subjects = len(np.unique(subj))\n",
    "num_partials = len(np.unique(psketchID))\n",
    "num_trials = len(np.unique(trialNum))\n",
    "num_sketches_per_subject = num_partials * num_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch sketches into subjects \n",
    "\n",
    "sketch_paths_batched = []\n",
    "for subject_i, subject in enumerate(np.unique(_subj)):\n",
    "    sketch_paths_batched.append(np.asarray(_sketch_paths)[np.asarray(_subj) == subject].tolist())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path, imsize=224, volatile=True, use_cuda=False):\n",
    "    im = Image.open(path)\n",
    "    im = im.convert('RGB')\n",
    "\n",
    "    loader = transforms.Compose([\n",
    "        transforms.Scale(imsize),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    im = Variable(loader(im), volatile=volatile)\n",
    "    im = im.unsqueeze(0)\n",
    "    if use_cuda:\n",
    "        im = im.cuda(cuda_device)\n",
    "    return im\n",
    "\n",
    "def sketch_generator(paths, imsize=224, use_cuda=use_cuda):\n",
    "    for path in paths:\n",
    "        sketch = load_image(path)\n",
    "        label = get_label_from_path(path)\n",
    "        yield (sketch, label)\n",
    "\n",
    "def _flatten(x):\n",
    "    return x.view(x.size(0), -1)\n",
    "   \n",
    "def extract_layer(x, layer_index):\n",
    "    x_conv1 = conv1(x)\n",
    "    if layer_index == 0:\n",
    "        return _flatten(x_conv1)\n",
    "    x_conv2 = conv2(x_conv1)\n",
    "    if layer_index == 1:\n",
    "        return _flatten(x_conv2)\n",
    "    x_conv3 = conv3(x_conv2)\n",
    "    if layer_index == 2:\n",
    "        return _flatten(x_conv3)\n",
    "    x_conv4 = conv4(x_conv3)\n",
    "    if layer_index == 3:\n",
    "        return _flatten(x_conv4)\n",
    "    x_conv5 = conv5(x_conv4)\n",
    "    x_conv5_flat = _flatten(x_conv5)\n",
    "    if layer_index == 4:\n",
    "        return x_conv5_flat\n",
    "    x_fc6 = fc6(x_conv5_flat)\n",
    "    if layer_index == 5:\n",
    "        return x_fc6\n",
    "    x_fc7 = fc7(x_fc6)\n",
    "    if layer_index == 6:\n",
    "        return x_fc7\n",
    "    x_fc8 = fc8(x_fc7)\n",
    "    if layer_index == 7:\n",
    "        return x_fc8\n",
    "    \n",
    "def extract_features_and_classes(domain, num_images, layer_index):\n",
    "\n",
    "    generator = sketch_generator(domain,imsize=224,use_cuda=use_cuda)\n",
    "    # initialize image and label matrices\n",
    "    Features = []\n",
    "    Labels = []\n",
    "    n = 0\n",
    "    quit = False \n",
    "\n",
    "    # generate batches of imagees and labels    \n",
    "    if generator:\n",
    "        while True:    \n",
    "            batch_size = 62\n",
    "            image_batch = Variable(torch.zeros(batch_size, 3, 224, 224))\n",
    "            if use_cuda:\n",
    "                image_batch = image_batch.cuda(cuda_device)                \n",
    "            label_batch = []   \n",
    "            if n%5==0:\n",
    "                print('Batch {}'.format(n + 1))            \n",
    "            for b in range(batch_size):\n",
    "                try:\n",
    "                    image, label = generator.next()\n",
    "                    image_batch[b] = image   \n",
    "                    label_batch.append(label)\n",
    "                except StopIteration:\n",
    "                    quit = True\n",
    "                    print 'stopped!'\n",
    "                    break                \n",
    "                \n",
    "            if n == num_images//batch_size:\n",
    "                image_batch = image_batch.narrow(0,0,b)\n",
    "                label_batch = label_batch[:b + 1] \n",
    "            n = n + 1       \n",
    "\n",
    "            # extract features from batch\n",
    "            image_batch = extract_layer(image_batch, layer_index)                        \n",
    "            image_batch = image_batch.cpu().data.numpy()\n",
    "\n",
    "            if len(Features)==0:\n",
    "                Features = image_batch\n",
    "            else:\n",
    "                Features = np.vstack((Features,image_batch))\n",
    "            Labels.append(label_batch)\n",
    "\n",
    "            if n == num_images//batch_size + 1:\n",
    "                break\n",
    "    Labels = np.array([item for sublist in Labels for item in sublist])\n",
    "    return Features, Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sketch features for subject 0110171_neurosketch...\n",
      "Batch 1\n",
      "Batch 6\n",
      "Batch 11\n",
      "stopped!\n",
      "Extracting sketch features for subject 0118171_neurosketch...\n",
      "Batch 1\n",
      "Batch 6\n",
      "Batch 11\n",
      "stopped!\n"
     ]
    }
   ],
   "source": [
    "# run extract features and build csv's per subject\n",
    "# csv's shoudl be based on the original csv from sketch_data (match subj accordingly. \n",
    "for subject_i, subject in enumerate(np.unique(_subj)):\n",
    "    metadata_file = '/home/rslee/sketch_data/{:s}/{:s}_metadata.csv'.format(subject, subject)\n",
    "    metadata_raw = pd.read_csv(metadata_file)\n",
    "    metadata = pd.concat([metadata_raw]*num_partials,  ignore_index=True).sort_values('trial').reset_index(drop=True)\n",
    "    metadata['Unnamed: 0'] = metadata.index.values\n",
    "\n",
    "    # add in partialID \n",
    "    metadata['partial_ID'] = np.asarray(_psketchID)[np.asarray(_subj) == subject]\n",
    "    \n",
    "    # rearrange columns \n",
    "    cols = metadata.columns.tolist()\n",
    "    cols = cols[:7] + cols[-1:] + cols[7:-1]\n",
    "    metadata = metadata[cols]\n",
    "    \n",
    "    dir_path = '/tigress/rslee/partial_s_mini/' + subject + '/'\n",
    "    metadata_path_to_save = dir_path + subject + '_metadata.csv'\n",
    "    pool5_path_to_save = dir_path + subject + '_pool5.p'\n",
    "    \n",
    "    metadata.to_csv(metadata_path_to_save)\n",
    "    \n",
    "    print('Extracting sketch features for subject ' + subject + '...')\n",
    "    SF_i , SL = extract_features_and_classes(sketch_paths_batched[subject_i], num_sketches_per_subject, 4)\n",
    "    pickle.dump(SF_i, open( pool5_path_to_save, \"wb\" ) )\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rslee/partial_s_mini/0110171_neurosketch'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.dirname(sketch_paths_batched[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
