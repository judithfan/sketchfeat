{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jefan 8/28/17\n",
    "# purpose: extract training phase metadata and sketches produced by participants\n",
    "# in fMRI training study (aka 'neurosketch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/judithfan/anaconda/lib/python2.7/site-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import base64\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "from skimage import data, io, filters\n",
    "import cStringIO\n",
    "import pandas as pd\n",
    "import pymongo as pm ## first establish ssh tunnel to Amazon EC2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in experimental design pickle file\n",
    "import cPickle\n",
    "mdtd = cPickle.load(open('morph_drawing_training_design.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mongo globals\n",
    "conn = pm.MongoClient(port=20809)\n",
    "DBNAME = conn['during_morph_drawing_recognition']\n",
    "COLNAME = DBNAME['fmri3.files']\n",
    "coll=COLNAME\n",
    "DATADIR = 'neurosketch_data_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get worker list\n",
    "patient_ids_1 = ['1121161_neurosketch', '1130161_neurosketch', \n",
    "'1201161_neurosketch', '1202161_neurosketch', '1203161_neurosketch',\n",
    "'1206161_neurosketch', '1206162_neurosketch','1206163_neurosketch',\n",
    "'1207161_neurosketch','1207162_neurosketch']\n",
    "patient_ids_2 = ['1207162_neurosketch']\n",
    "patient_ids_3 = ['0110171_neurosketch', '0110172_neurosketch',\n",
    "'0111171_neurosketch','0112171_neurosketch', '0112172_neurosketch','0112173_neurosketch',\n",
    "'0113171_neurosketch','0115172_neurosketch','0115174_neurosketch','0117171_neurosketch',\n",
    "'0118171_neurosketch','0118172_neurosketch','0119171_neurosketch','0119172_neurosketch',\n",
    "'0119173_neurosketch', '0119174_neurosketch','0120171_neurosketch','0120172_neurosketch',\n",
    "'0120173_neurosketch','0123171_neurosketch','0123172_neurosketch','0123173_neurosketch',\n",
    "'0124171_neurosketch','0125171_neurosketch','0125172_neurosketch']\n",
    "\n",
    "patient_ids = patient_ids_1 + patient_ids_2 + patient_ids_3\n",
    "workers = patient_ids\n",
    "\n",
    "## manually add 2nd half of 0123172 to list ('0123172_neurosketch_2'), and merge later\n",
    "workers = workers + ['0123172_neurosketch_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = workers[0]\n",
    "these = coll.find({'wID': w}).sort('trialNum')   \n",
    "## manually add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123172_neurosketch_2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_workers = workers[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now analyzing 0125172_neurosketch ...\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_320_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_321_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_322_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_323_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_324_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_325_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_326_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_327_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_328_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_329_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_330_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_331_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_332_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_333_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_334_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_335_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_336_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_337_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_338_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_339_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_340_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_341_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_342_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_343_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_344_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_345_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_346_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_347_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_348_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_349_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_350_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_351_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_352_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_353_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_354_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_355_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_356_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_357_bed\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_358_chair\n",
      "Saving to data/0125172_neurosketch/0125172_neurosketch_trial_359_bed\n",
      "Now analyzing 0123172_neurosketch_2 ...\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_338_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_339_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_340_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_341_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_342_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_343_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_344_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_345_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_346_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_347_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_348_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_349_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_350_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_351_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_352_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_353_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_354_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_355_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_356_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_357_chair\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_358_bench\n",
      "Saving to data/0123172_neurosketch_2/0123172_neurosketch_2_trial_359_chair\n"
     ]
    }
   ],
   "source": [
    "for w in _workers:\n",
    "    try:\n",
    "        print 'Now analyzing ' + w + ' ...'\n",
    "        # retrieve this participant's records from mongo\n",
    "        these = coll.find({'wID': w}).sort('trialNum')   \n",
    "\n",
    "        wID = []\n",
    "        phase = []\n",
    "        version = []\n",
    "        category = []\n",
    "        viewpoint = []\n",
    "        trial = []\n",
    "        trialDuration = []\n",
    "        target = []\n",
    "        competitor = []\n",
    "        svgString = []\n",
    "        pngString = []\n",
    "\n",
    "        # loop through training trials and save relevant metadata\n",
    "        for this in these:\n",
    "            if this['phase']=='training':\n",
    "                wID.append(this['wID'])\n",
    "                phase.append(this['phase'])\n",
    "                version.append(int(this['versionNum']))\n",
    "                category.append(this['category'])\n",
    "                viewpoint.append(int(this['viewpoint']))\n",
    "                trial.append(int(this['trialNum']))\n",
    "                trialDuration.append(float(this['trialDuration']))\n",
    "                _target = gm.get_object_name(2,gm.get_object_index(this['morphline'],this['morphnum']))\n",
    "                target.append(_target)\n",
    "                trained_set = gm.getEndpoints(this['morphline'])\n",
    "                _competitor = [i for i in trained_set if i != _target]\n",
    "                competitor.append(_competitor[0])\n",
    "                svgString.append(this['json'])\n",
    "                pngString.append(this['imgData'])\n",
    "        ## make pandas dataframe to store metadata\n",
    "        X = pd.DataFrame([wID,phase,version,category,viewpoint,trial,trialDuration,\n",
    "                         target,competitor,svgString,pngString])\n",
    "        X = X.transpose()\n",
    "        X.columns = ['wID','phase','version','category','viewpoint','trial','trialDuration',\n",
    "                    'target','competitor','svgString','pngString']\n",
    "\n",
    "        ## save out dataframe to csv\n",
    "        pathdir = os.path.join('data',w)\n",
    "        ## save out image as png\n",
    "        if not os.path.exists(pathdir):\n",
    "            os.makedirs(pathdir)\n",
    "        fname = w + '_metadata.csv'\n",
    "        filepath = os.path.join(pathdir,fname)\n",
    "        X.to_csv(filepath)  \n",
    "        ## loop through all sketches and save out as png's in subject specific folders\n",
    "        for t in trial:\n",
    "            imgData = X[X['trial']==t].pngString.values[0]\n",
    "            im = Image.open(cStringIO.StringIO(base64.b64decode(imgData)))\n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "            p = plt.subplot(1,1,1)\n",
    "            plt.imshow(im)\n",
    "            k = p.get_xaxis().set_ticklabels([])\n",
    "            k = p.get_yaxis().set_ticklabels([])\n",
    "            k = p.get_xaxis().set_ticks([])\n",
    "            k = p.get_yaxis().set_ticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "            pathdir = os.path.join('data',X[X['trial']==t].wID.values[0])\n",
    "            ## save out image as png\n",
    "            if not os.path.exists(pathdir):\n",
    "                os.makedirs(pathdir)\n",
    "            fname = X[X['trial']==t].wID.values[0]  + '_trial_' + \\\n",
    "            str(X[X['trial']==t].trial.values[0]) + '_' + X[X['trial']==t].target.values[0]\n",
    "            filepath = os.path.join(pathdir,fname)\n",
    "            print 'Saving to ' + filepath\n",
    "            fig.savefig(filepath+'.png',bbox_inches='tight')  \n",
    "            plt.close(fig)\n",
    "    except:\n",
    "        print('Something went wrong with subject ' + w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## manually merge 0123172_neurosketch & 0123172_neurosketch_2 datasets because they had to be collected in two different javascript game sessions\n",
    "import shutil\n",
    "\n",
    "def manual_merge_0123172():\n",
    "    try:\n",
    "        shutil.move('data/0123172_neurosketch_2/', 'data/0123172_neurosketch/')\n",
    "        files = os.listdir('data/0123172_neurosketch/0123172_neurosketch_2')\n",
    "        ## move images\n",
    "        for f in files:\n",
    "            if f.endswith('.png'):\n",
    "                _f = f.split('_')[0] + '_' + f.split('_')[1] + '_' + f.split('_')[3] + '_' + f.split('_')[4] + '_' + f.split('_')[5]\n",
    "                shutil.copy(os.path.join('data/0123172_neurosketch/0123172_neurosketch_2',f),'data/0123172_neurosketch/' + _f)\n",
    "        ## now splice together pandas dataframe        \n",
    "        df1 = pd.read_csv('data/0123172_neurosketch/0123172_neurosketch_metadata.csv')\n",
    "        df2 = pd.read_csv('data/0123172_neurosketch/0123172_neurosketch_2/0123172_neurosketch_2_metadata.csv')\n",
    "        _df2 = df2[df2.trial>=340]\n",
    "        df = pd.concat([df1,_df2],ignore_index=True)        \n",
    "\n",
    "        # rename old truncated metadata csv\n",
    "        os.rename('data/0123172_neurosketch/0123172_neurosketch_metadata.csv','data/0123172_neurosketch/0123172_neurosketch_metadata_old.csv')\n",
    "        os.rename('data/0123172_neurosketch/0123172_neurosketch_metadata_old.csv','fragment_backup/0123172_neurosketch_metadata_old.csv')\n",
    "\n",
    "        # write out new repaired csv\n",
    "        df.to_csv('data/0123172_neurosketch/0123172_neurosketch_metadata.csv')\n",
    "\n",
    "        # clean up, move fragments to fragment folder\n",
    "        shutil.move('data/0123172_neurosketch/0123172_neurosketch_2/', 'fragment_backup/backup')\n",
    "    except:\n",
    "        print 'Maybe already did this... '\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
