{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "VGG_SIZE_X = 224\n",
    "VGG_SIZE_Y = 224\n",
    "VGG_SIZE_Z = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    u = X.mean(0)\n",
    "    std = np.maximum(X.std(0), 1e-5)\n",
    "    X = X - u\n",
    "    X = X / std\n",
    "    return (X, u, std)\n",
    "\n",
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path)\n",
    "              for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "def load_images(paths, num_sketches):\n",
    "    X = np.empty((num_sketches, VGG_SIZE_X * VGG_SIZE_Y* VGG_SIZE_Z), np.uint8)\n",
    "\n",
    "    for p_i, p in enumerate(paths):\n",
    "        im = Image.open(p)\n",
    "        im = im.convert('RGB')\n",
    "        im.thumbnail((VGG_SIZE_X, VGG_SIZE_Y), Image.ANTIALIAS)\n",
    "        img = PIL2array(im)\n",
    "\n",
    "        X[p_i, :] = img.flatten()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def PIL2array(img):\n",
    "\n",
    "    return np.array(img.getdata(),\n",
    "                    np.uint8).reshape(img.size[1], img.size[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will train the network on the baseline_sketches (or sketches from a different dataset)\n",
    "# TODO: maybe just use the direct matadata file. the only difference should be the \n",
    "\n",
    "# get metadata\n",
    "\n",
    "\n",
    "def get_train_label_from_path(path):\n",
    "    return path.split('/')[-1].split('_')[0]\n",
    "\n",
    "\n",
    "def get_train_viewpoint_from_path(path):\n",
    "    return path.split('/')[-1].split('_')[1]\n",
    "\n",
    "def get_train_ID_from_path(path):\n",
    "    return path.split('/')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "    \n",
    "# extract metadata\n",
    "path_to_train = '/home/rslee/baseline_sketches'\n",
    "train_paths = list_files(path_to_train)\n",
    "train_labels = map(get_train_label_from_path,train_paths)\n",
    "train_viewpoint = map(get_train_viewpoint_from_path, train_paths)\n",
    "train_ID = map(get_train_ID_from_path, train_paths)\n",
    "\n",
    "num_train = len(train_paths)\n",
    "\n",
    "# organize into dataframe\n",
    "Tr = pd.DataFrame([train_ID, train_labels, train_viewpoint, train_paths])\n",
    "Tr = Tr.transpose()\n",
    "Tr.columns = ['trainID', 'label', 'viewpoint', 'path']\n",
    "\n",
    "# Load all the data ahead of time\n",
    "\n",
    "X_train = load_images(train_paths, num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for testing data, we will test for every partial sketch. To just test this, let's just try one set of partial sketches\n",
    "def get_psketch_ID_from_path(path):\n",
    "    return path.split('/')[-1].split('.')[0]\n",
    "\n",
    "path_to_test = '/home/rslee/partial_sketches/0110171_neurosketch/bed_320'\n",
    "test_paths = list_files(path_to_test)\n",
    "test_psketch_ID = map(get_psketch_ID_from_path, test_paths)\n",
    "# sort by psketchID\n",
    "psketch_order = np.argsort(np.asarray(test_psketch_ID).astype(int))\n",
    "_test_paths = [test_paths[i] for i in psketch_order] \n",
    "\n",
    "\n",
    "\n",
    "test_label = 'bed' # hardcodign for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as first pass, no normalization \n",
    "\n",
    "for sketch in _test_paths:\n",
    "    logreg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = logreg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
